# FedRN: Exploiting k-Reliable Neighbors Towards Robust Federated Learning


## Abstract
Robustness is becoming another important challenge of fed-erated  learning  in  that  the  data  collection  process  in  eachclient is naturally accompanied by noisy labels. However, itis far more complex and challenging owing to varying lev-els of data heterogeneity and noise over clients, which dras-tically exacerbates the client-to-client performance discrep-ancy.  In  this  work,  we  propose  a  robust  federated  learningmethod  called  FedRN,  which  exploits  k-reliable  neighborswith high data expertise and similarity. They help mitigate thegap between low- and high-performance clients by trainingwith only the selected set of clean examples, which identifiedby their emsembled mixture model. We demonstrate the su-perioity of FedRN by extensive evaluation on three real-worldor synthetic benchmark datasets. Compared with existing ro-bust training methods, the results showed that FedRN signif-icantly improved the test accuracy in the presence of noisylabels.

